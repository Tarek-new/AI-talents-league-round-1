{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, OneHotEncoder, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import ydata_profiling as ydata"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e4f79ff6dd1f831f",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"../AI Talents League - Round 1/train.csv\")\n",
    "\n",
    "### 1. Exploratory Data Analysis (EDA) ###\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "display(df.head())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d4a6a2ed972807e",
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d394a78b261d2b8",
   "metadata": {},
   "source": "ydata.ProfileReport(df).to_file(\"profile_report.html\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cef7f5ff9b6cc18",
   "metadata": {},
   "source": [
    "df.duplicated().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f78f0ef3ccbc4f5c",
   "metadata": {},
   "source": [
    "#Check for missing values\n",
    "print(\"Missing Values Per Column %:\")\n",
    "print(df.isnull().sum()*100/len(df.index))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf289e573c4fc1a3",
   "metadata": {},
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature Selection\n",
    "X = df.drop(columns=[\"Y\", \"X1\"])  # Drop Target and Unnecessary Column\n",
    "y = df[\"Y\"]"
   ],
   "id": "c9b59bba9fb45f69",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc25965d967014d5",
   "metadata": {},
   "source": "X[\"X9\"].value_counts()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "312fd70195468d40",
   "metadata": {},
   "source": [
    "# Handling Missing Values\n",
    "X[\"X9\"] = X[\"X9\"].fillna(\"Missing\")\n",
    "X[\"X2\"] = X[\"X2\"].fillna(X[\"X2\"].mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f39989640f321c0",
   "metadata": {},
   "source": [
    "# Identifying categorical & numerical features\n",
    "num_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = X.select_dtypes(exclude=[np.number]).columns.tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Compute correlation matrix\n",
    "corr_matrix = X[num_features].corr()\n",
    "sns.heatmap(corr_matrix.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ],
   "id": "13e74ee1ca610d82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Target Variable Distribution\n",
    "sns.histplot(y, kde=True, bins=30)\n",
    "plt.title(\"Target Variable Distribution\")\n",
    "plt.show()"
   ],
   "id": "1db58f3523681b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2960d8d7639d7598",
   "metadata": {},
   "source": [
    "# Detect Outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for col in num_features:\n",
    "    sns.boxplot(data=df[[col]],  x=col)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f\"Boxplot for Outlier Detection of {col}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e786d6e794880541",
   "metadata": {},
   "source": [
    "# Function to detect outliers using IQR\n",
    "outliers = {}\n",
    "for col in num_features:\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the bounds for non-outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Detect outliers: data points outside the bounds\n",
    "        outlier_condition = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "        num_outliers = outlier_condition.sum()\n",
    "\n",
    "        # Calculate percentage of outliers\n",
    "        outliers[col] = {\n",
    "            'num_outliers': num_outliers,\n",
    "            'percentage_outliers': (num_outliers / len(df)) * 100\n",
    "        }\n",
    "\n",
    "# Get outlier information for each numerical feature\n",
    "outlier_info = outliers\n",
    "\n",
    "# Print outliers information\n",
    "for col, info in outlier_info.items():\n",
    "    print(f\"Feature: {col}\")\n",
    "    print(f\"Number of Outliers: {info['num_outliers']}\")\n",
    "    print(f\"Percentage of Outliers: {info['percentage_outliers']:.2f}%\")\n",
    "    print(\"-\" * 40)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pairplot for Feature Relationships\n",
    "sns.pairplot(df, diag_kind=\"kde\")\n",
    "plt.show()"
   ],
   "id": "47ad5924b4340b15",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c06a21da721cca40",
   "metadata": {},
   "source": [
    "# Binning Feature \"X8\" into categories\n",
    "bins = [1980, 1990, 2000, 2010]\n",
    "labels = [\"Very Old\", \"Old\", \"Recent\"]\n",
    "X[\"X8\"] = pd.cut(df[\"X8\"], bins=bins, labels=labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "#y=transformer.fit_transform(target.values.reshape(-1,1))\n",
    "#y = target.ravel()"
   ],
   "id": "1918d5f798e11126",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9df6cbd8a27cb9dd",
   "metadata": {},
   "source": "X[\"X4\"]=transformer.fit_transform(X[\"X4\"].values.reshape(-1,1))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identifying categorical & numerical features\n",
    "num_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n"
   ],
   "id": "9c9b39e3b97fd950",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bffe16063518aeaa",
   "metadata": {},
   "source": [
    "# Scaling Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X[num_features] = scaler.fit_transform(X[num_features])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "787fff3c43c2d1c1",
   "metadata": {},
   "source": [
    "# Standardizing the values to two categories: 'Low Fat' and 'Regular'\n",
    "X[\"X3\"] = X[\"X3\"].str.lower().str.strip()  # Convert to lowercase and remove extra spaces\n",
    "\n",
    "# Map different spellings to a consistent format\n",
    "X[\"X3\"] = X[\"X3\"].replace({\n",
    "    'low fat': 'Low Fat',\n",
    "    'lf': 'Low Fat',\n",
    "    'regular': 'Regular',\n",
    "    'reg': 'Regular'\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "352a2cf42f72f05d",
   "metadata": {},
   "source": [
    " Encoding Categorical Features\n",
    "ordinal_encoders = {\n",
    "   \"X9\": OrdinalEncoder(categories=[[\"Missing\", \"Small\", \"Medium\", \"High\"]]),\n",
    "   \"X8\": OrdinalEncoder(categories=[[\"Very Old\", \"Old\", \"Recent\"]])\n",
    "}\n",
    "\n",
    "for col, encoder in ordinal_encoders.items():\n",
    "    X[col] = encoder.fit_transform(X[[col]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eba9f4c925c4e223",
   "metadata": {},
   "source": [
    "# One-Hot Encoding Other Categorical Features\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "one_hot_features = one_hot_encoder.fit_transform(X[[\"X3\", \"X5\", \"X7\", \"X10\", \"X11\"]])\n",
    "one_hot_df = pd.DataFrame(one_hot_features, columns=one_hot_encoder.get_feature_names_out())\n",
    "X = X.drop(columns=[\"X3\", \"X5\", \"X7\", \"X10\", \"X11\"]).reset_index(drop=True)\n",
    "X = pd.concat([X, one_hot_df.reset_index(drop=True)], axis=1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4ec685917334bd6",
   "metadata": {},
   "source": "X",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "e528ceb946168dd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter grids for each model\n",
    "param_grids = {\n",
    "    'Linear Regression': {},\n",
    "    'Ridge Regression': {\n",
    "        'alpha': [0.1, 1, 10, 100],\n",
    "        'solver': ['auto', 'saga', ]\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'alpha': [0.01, 0.1, 0.5, 1, 10],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 20, 50],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': [ 'sqrt', 'log2']\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'subsample': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.7, 0.8],\n",
    "        'colsample_bytree': [0.3, 0.],\n",
    "        'gamma': [0, 0.1],\n",
    "        'reg_alpha': [0, 0.1],\n",
    "        'reg_lambda': [1, 5],\n",
    "        'min_child_weight': [1, 3]\n",
    "    },\n",
    "\n",
    "    'Support Vector Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "        'epsilon': [0.01, 0.05, 0.1, 0.2]\n",
    "    }\n",
    "}"
   ],
   "id": "e3a7e775352cca12",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "530fd2e4c5860974",
   "metadata": {},
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    #'XGBoost':XGBRegressor(tree_method='hist'),\n",
    "    'Support Vector Regression': SVR()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_results = {}\n",
    "best_models = {}\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Training Models\"):\n",
    "    print(f\"Running GridSearchCV for {name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='neg_mean_absolute_error', n_jobs=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_results[name] = -grid_search.best_score_  # Negating the score to convert back from negative MAE\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "\n",
    "# Print out the best results\n",
    "for name in best_results:\n",
    "    print(f\"{name}: Best MAE = {best_results[name]}\")\n",
    "\n",
    "# Select the best model\n",
    "best_model_name = min(best_results, key=best_results.get)\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"Best Model: {best_model_name} with MAE of {best_results[best_model_name]}\")\n"
   ],
   "id": "19125269d07f815e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df1 = pd.DataFrame({'Actual': y_test, 'Predicted':y_train})\n",
    "df2 = df1.head(10)\n",
    "df2.plot(kind = 'bar')"
   ],
   "id": "34f70438bb0d9681",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "153bcfbdbbddd868",
   "metadata": {},
   "source": [
    "test_df=pd.read_csv(\"../AI Talents League - Round 1/test.csv\")\n",
    "test_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df.drop(columns=[\"X1\"], inplace=True)\n",
    "test_df[\"X3\"].unique()\n"
   ],
   "id": "85ef3147ff2fb092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standardizing the values to two categories: 'Low Fat' and 'Regular'\n",
    "test_df[\"X3\"] = test_df[\"X3\"].str.lower().str.strip()  # Convert to lowercase and remove extra spaces\n",
    "\n",
    "# Map different spellings to a consistent format\n",
    "test_df[\"X3\"] = test_df[\"X3\"].replace({\n",
    "    'low fat': 'Low Fat',\n",
    "    'lf': 'Low Fat',\n",
    "    'regular': 'Regular',\n",
    "    'reg': 'Regular'\n",
    "})\n"
   ],
   "id": "336762a9a6751701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_df.isnull().sum()/len(df)\n",
   "id": "bd51a8cdf15e4789",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df.fillna({\"X2\": test_df[\"X2\"].mean(), \"X9\": \"Missing\"}, inplace=True)\n",
    "test_df[\"X8\"] = pd.cut(test_df[\"X8\"], bins=bins, labels=labels)"
   ],
   "id": "63a881b42009e203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_features=test_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "catergical_features=test_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "test_df[\"X4\"]=transformer.fit_transform(test_df[\"X4\"].values.reshape(-1,1))\n",
    "\n",
    "test_df[numerical_features]=scaler.fit_transform(test_df[numerical_features])\n",
    "\n",
    "ordinal_enconder_X9=OrdinalEncoder(categories=[['Missing','Small', 'Medium', 'High']])\n",
    "test_df[\"X9\"]=ordinal_enconder_X9.fit_transform(test_df[[\"X9\"]])\n",
    "ordinal_enconder_X8=OrdinalEncoder(categories=[['Very Old', 'Old', 'Recent']])\n",
    "test_df[\"X8\"]=ordinal_enconder_X8.fit_transform(test_df[[\"X8\"]])\n",
    "\n",
    "one_hot_encoder=OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n",
    "categorical_cols=['X3','X5','X7','X10','X11']\n",
    "one_hot_features=one_hot_encoder.fit_transform(test_df[categorical_cols])\n",
    "one_hot_df=pd.DataFrame(one_hot_features,columns=one_hot_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Reset index to match original DataFrame\n",
    "one_hot_df.index = test_df.index\n",
    "\n",
    "# Drop original categorical columns\n",
    "test_df.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Concatenate the new one-hot encoded DataFrame with the original features\n",
    "test_df = pd.concat([test_df, one_hot_df], axis=1)\n",
    "test_df"
   ],
   "id": "9d8623fc00586029",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = best_model.predict(test_df)\n",
    "pd.DataFrame({'row_id': test_df.index, 'Y': y_pred}).to_csv('../AI Talents League - Round 1/predictionsTXGBOOST.csv', index=False)\n"
   ],
   "id": "7a97cb2654ae1026",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e57b574f7be4fcd8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
