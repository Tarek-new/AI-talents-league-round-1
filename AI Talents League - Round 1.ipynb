{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:32:12.998625Z",
     "start_time": "2025-02-06T11:32:12.980871Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder, OneHotEncoder, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import ydata_profiling as ydata\n",
    "from sklearn.model_selection import cross_val_score\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "e4f79ff6dd1f831f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:31:04.236097Z",
     "start_time": "2025-02-06T11:31:04.155880Z"
    }
   },
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"../AI Talents League - Round 1/train.csv\")\n",
    "\n",
    "### 1. Exploratory Data Analysis (EDA) ###\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "display(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (6000, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      X1     X2       X3        X4                     X5        X6      X7  \\\n",
       "0  FDA15   9.30  Low Fat  0.016047                  Dairy  249.8092  OUT049   \n",
       "1  DRC01   5.92  Regular  0.019278            Soft Drinks   48.2692  OUT018   \n",
       "2  FDN15  17.50  Low Fat  0.016760                   Meat  141.6180  OUT049   \n",
       "3  FDX07  19.20  Regular  0.000000  Fruits and Vegetables  182.0950  OUT010   \n",
       "4  NCD19   8.93  Low Fat  0.000000              Household   53.8614  OUT013   \n",
       "\n",
       "     X8      X9     X10                X11     Y  \n",
       "0  1999  Medium  Tier 1  Supermarket Type1  8.23  \n",
       "1  2009  Medium  Tier 3  Supermarket Type2  6.09  \n",
       "2  1999  Medium  Tier 1  Supermarket Type1  7.65  \n",
       "3  1998     NaN  Tier 3      Grocery Store  6.60  \n",
       "4  1987    High  Tier 3  Supermarket Type1  6.90  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>7.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>6.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>6.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "6d4a6a2ed972807e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:31:09.615380Z",
     "start_time": "2025-02-06T11:31:09.575923Z"
    }
   },
   "source": [
    "df.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                X2           X4           X6           X8            Y\n",
       "count  4994.000000  6000.000000  6000.000000  6000.000000  6000.000000\n",
       "mean     12.956536     0.066333   141.228200  1997.840333     7.303403\n",
       "std       4.658851     0.051492    62.540569     8.334412     1.014361\n",
       "min       4.555000     0.000000    31.290000  1985.000000     3.510000\n",
       "25%       8.895000     0.027030    94.037650  1987.000000     6.750000\n",
       "50%      12.800000     0.054620   143.197000  1999.000000     7.500000\n",
       "75%      17.100000     0.095154   186.522050  2004.000000     8.040000\n",
       "max      21.350000     0.328391   266.888400  2009.000000     9.400000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>X4</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4994.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>6000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.956536</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>141.228200</td>\n",
       "      <td>1997.840333</td>\n",
       "      <td>7.303403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.658851</td>\n",
       "      <td>0.051492</td>\n",
       "      <td>62.540569</td>\n",
       "      <td>8.334412</td>\n",
       "      <td>1.014361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>3.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.895000</td>\n",
       "      <td>0.027030</td>\n",
       "      <td>94.037650</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.800000</td>\n",
       "      <td>0.054620</td>\n",
       "      <td>143.197000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.100000</td>\n",
       "      <td>0.095154</td>\n",
       "      <td>186.522050</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>8.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>9.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "9d394a78b261d2b8",
   "metadata": {},
   "source": "ydata.ProfileReport(df).to_file(\"profile_report.html\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cef7f5ff9b6cc18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:31:14.040144Z",
     "start_time": "2025-02-06T11:31:14.021562Z"
    }
   },
   "source": [
    "df.duplicated().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:46:00.914163Z",
     "start_time": "2025-02-06T11:38:36.898441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Establishing a baseline by training the model on the un-augmented dataset\n",
    "X = df.drop(columns=[\"Y\",\"X1\"])\n",
    "y = df[\"Y\"]\n",
    "categorical_features=X.select_dtypes(exclude=[np.number])\n",
    "X = pd.get_dummies(categorical_features, drop_first=True)\n",
    "# Train and score baseline model\n",
    "baseline = RandomForestRegressor(criterion=\"absolute_error\", random_state=0)\n",
    "baseline_score = cross_val_score(\n",
    "    baseline, X, y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "baseline_score = -1 * baseline_score.mean()\n",
    "\n",
    "print(f\"MAE Baseline Score: {baseline_score:.4}\")"
   ],
   "id": "c73c2656782b8237",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE Baseline Score: 0.6161\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "f78f0ef3ccbc4f5c",
   "metadata": {},
   "source": [
    "#Check for missing values\n",
    "print(\"Missing Values Per Column %:\")\n",
    "print(df.isnull().sum()*100/len(df.index))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bf289e573c4fc1a3",
   "metadata": {},
   "source": [
    "df.info()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Feature Selection\n",
    "X = df.drop(columns=[\"Y\", \"X1\"])  # Drop Target and Unnecessary Column\n",
    "y = df[\"Y\"]"
   ],
   "id": "c9b59bba9fb45f69",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc25965d967014d5",
   "metadata": {},
   "source": "X[\"X9\"].value_counts()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "312fd70195468d40",
   "metadata": {},
   "source": [
    "# Handling Missing Values\n",
    "X[\"X9\"] = X[\"X9\"].fillna(\"Missing\")\n",
    "X[\"X2\"] = X[\"X2\"].fillna(X[\"X2\"].mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f39989640f321c0",
   "metadata": {},
   "source": [
    "# Identifying categorical & numerical features\n",
    "num_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = X.select_dtypes(exclude=[np.number]).columns.tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Compute correlation matrix\n",
    "corr_matrix = X[num_features].corr()\n",
    "sns.heatmap(corr_matrix.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ],
   "id": "13e74ee1ca610d82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Target Variable Distribution\n",
    "sns.histplot(y, kde=True, bins=30)\n",
    "plt.title(\"Target Variable Distribution\")\n",
    "plt.show()"
   ],
   "id": "1db58f3523681b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2960d8d7639d7598",
   "metadata": {},
   "source": [
    "# Detect Outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "for col in num_features:\n",
    "    sns.boxplot(data=df[[col]],  x=col)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f\"Boxplot for Outlier Detection of {col}\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e786d6e794880541",
   "metadata": {},
   "source": [
    "# Function to detect outliers using IQR\n",
    "outliers = {}\n",
    "for col in num_features:\n",
    "        # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the bounds for non-outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Detect outliers: data points outside the bounds\n",
    "        outlier_condition = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "        num_outliers = outlier_condition.sum()\n",
    "\n",
    "        # Calculate percentage of outliers\n",
    "        outliers[col] = {\n",
    "            'num_outliers': num_outliers,\n",
    "            'percentage_outliers': (num_outliers / len(df)) * 100\n",
    "        }\n",
    "\n",
    "# Get outlier information for each numerical feature\n",
    "outlier_info = outliers\n",
    "\n",
    "# Print outliers information\n",
    "for col, info in outlier_info.items():\n",
    "    print(f\"Feature: {col}\")\n",
    "    print(f\"Number of Outliers: {info['num_outliers']}\")\n",
    "    print(f\"Percentage of Outliers: {info['percentage_outliers']:.2f}%\")\n",
    "    print(\"-\" * 40)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pairplot for Feature Relationships\n",
    "sns.pairplot(df, diag_kind=\"kde\")\n",
    "plt.show()"
   ],
   "id": "47ad5924b4340b15",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c06a21da721cca40",
   "metadata": {},
   "source": [
    "# Binning Feature \"X8\" into categories\n",
    "bins = [1980, 1990, 2000, 2010]\n",
    "labels = [\"Very Old\", \"Old\", \"Recent\"]\n",
    "X[\"X8\"] = pd.cut(df[\"X8\"], bins=bins, labels=labels)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformer = PowerTransformer(method='yeo-johnson')\n",
    "#y=transformer.fit_transform(target.values.reshape(-1,1))\n",
    "#y = target.ravel()"
   ],
   "id": "1918d5f798e11126",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9df6cbd8a27cb9dd",
   "metadata": {},
   "source": "X[\"X4\"]=transformer.fit_transform(X[\"X4\"].values.reshape(-1,1))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Identifying categorical & numerical features\n",
    "num_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n"
   ],
   "id": "9c9b39e3b97fd950",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bffe16063518aeaa",
   "metadata": {},
   "source": [
    "# Scaling Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X[num_features] = scaler.fit_transform(X[num_features])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "787fff3c43c2d1c1",
   "metadata": {},
   "source": [
    "# Standardizing the values to two categories: 'Low Fat' and 'Regular'\n",
    "X[\"X3\"] = X[\"X3\"].str.lower().str.strip()  # Convert to lowercase and remove extra spaces\n",
    "\n",
    "# Map different spellings to a consistent format\n",
    "X[\"X3\"] = X[\"X3\"].replace({\n",
    "    'low fat': 'Low Fat',\n",
    "    'lf': 'Low Fat',\n",
    "    'regular': 'Regular',\n",
    "    'reg': 'Regular'\n",
    "})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "352a2cf42f72f05d",
   "metadata": {},
   "source": [
    " Encoding Categorical Features\n",
    "ordinal_encoders = {\n",
    "   \"X9\": OrdinalEncoder(categories=[[\"Missing\", \"Small\", \"Medium\", \"High\"]]),\n",
    "   \"X8\": OrdinalEncoder(categories=[[\"Very Old\", \"Old\", \"Recent\"]])\n",
    "}\n",
    "\n",
    "for col, encoder in ordinal_encoders.items():\n",
    "    X[col] = encoder.fit_transform(X[[col]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eba9f4c925c4e223",
   "metadata": {},
   "source": [
    "# One-Hot Encoding Other Categorical Features\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "one_hot_features = one_hot_encoder.fit_transform(X[[\"X3\", \"X5\", \"X7\", \"X10\", \"X11\"]])\n",
    "one_hot_df = pd.DataFrame(one_hot_features, columns=one_hot_encoder.get_feature_names_out())\n",
    "X = X.drop(columns=[\"X3\", \"X5\", \"X7\", \"X10\", \"X11\"]).reset_index(drop=True)\n",
    "X = pd.concat([X, one_hot_df.reset_index(drop=True)], axis=1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4ec685917334bd6",
   "metadata": {},
   "source": "X",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "e528ceb946168dd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the parameter grids for each model\n",
    "param_grids = {\n",
    "    'Linear Regression': {},\n",
    "    'Ridge Regression': {\n",
    "        'alpha': [0.1, 1, 10, 100],\n",
    "        'solver': ['auto', 'saga', ]\n",
    "    },\n",
    "    'Lasso Regression': {\n",
    "        'alpha': [0.01, 0.1, 0.5, 1, 10],\n",
    "        'max_iter': [1000, 2000, 3000]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [None, 10, 20, 50],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': [ 'sqrt', 'log2']\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [3, 5, 10],\n",
    "        'subsample': [0.7, 0.8, 0.9]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.7, 0.8],\n",
    "        'colsample_bytree': [0.3, 0.],\n",
    "        'gamma': [0, 0.1],\n",
    "        'reg_alpha': [0, 0.1],\n",
    "        'reg_lambda': [1, 5],\n",
    "        'min_child_weight': [1, 3]\n",
    "    },\n",
    "\n",
    "    'Support Vector Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "        'epsilon': [0.01, 0.05, 0.1, 0.2]\n",
    "    }\n",
    "}"
   ],
   "id": "e3a7e775352cca12",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "530fd2e4c5860974",
   "metadata": {},
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Lasso Regression': Lasso(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    #'XGBoost':XGBRegressor(tree_method='hist'),\n",
    "    'Support Vector Regression': SVR()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_results = {}\n",
    "best_models = {}\n",
    "\n",
    "# Perform GridSearchCV for each model\n",
    "\n",
    "for name, model in tqdm(models.items(), desc=\"Training Models\"):\n",
    "    print(f\"Running GridSearchCV for {name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grids[name], cv=5, scoring='neg_mean_absolute_error', n_jobs=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_results[name] = -grid_search.best_score_  # Negating the score to convert back from negative MAE\n",
    "    best_models[name] = grid_search.best_estimator_\n",
    "\n",
    "# Print out the best results\n",
    "for name in best_results:\n",
    "    print(f\"{name}: Best MAE = {best_results[name]}\")\n",
    "\n",
    "# Select the best model\n",
    "best_model_name = min(best_results, key=best_results.get)\n",
    "best_model = best_models[best_model_name]\n",
    "print(f\"Best Model: {best_model_name} with MAE of {best_results[best_model_name]}\")\n"
   ],
   "id": "19125269d07f815e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df1 = pd.DataFrame({'Actual': y_test, 'Predicted':y_train})\n",
    "df2 = df1.head(10)\n",
    "df2.plot(kind = 'bar')"
   ],
   "id": "34f70438bb0d9681",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "153bcfbdbbddd868",
   "metadata": {},
   "source": [
    "test_df=pd.read_csv(\"../AI Talents League - Round 1/test.csv\")\n",
    "test_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df.drop(columns=[\"X1\"], inplace=True)\n",
    "test_df[\"X3\"].unique()\n"
   ],
   "id": "85ef3147ff2fb092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standardizing the values to two categories: 'Low Fat' and 'Regular'\n",
    "test_df[\"X3\"] = test_df[\"X3\"].str.lower().str.strip()  # Convert to lowercase and remove extra spaces\n",
    "\n",
    "# Map different spellings to a consistent format\n",
    "test_df[\"X3\"] = test_df[\"X3\"].replace({\n",
    "    'low fat': 'Low Fat',\n",
    "    'lf': 'Low Fat',\n",
    "    'regular': 'Regular',\n",
    "    'reg': 'Regular'\n",
    "})\n"
   ],
   "id": "336762a9a6751701",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_df.isnull().sum()/len(df)\n",
   "id": "bd51a8cdf15e4789",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_df.fillna({\"X2\": test_df[\"X2\"].mean(), \"X9\": \"Missing\"}, inplace=True)\n",
    "test_df[\"X8\"] = pd.cut(test_df[\"X8\"], bins=bins, labels=labels)"
   ],
   "id": "63a881b42009e203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numerical_features=test_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "catergical_features=test_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "test_df[\"X4\"]=transformer.fit_transform(test_df[\"X4\"].values.reshape(-1,1))\n",
    "\n",
    "test_df[numerical_features]=scaler.fit_transform(test_df[numerical_features])\n",
    "\n",
    "ordinal_enconder_X9=OrdinalEncoder(categories=[['Missing','Small', 'Medium', 'High']])\n",
    "test_df[\"X9\"]=ordinal_enconder_X9.fit_transform(test_df[[\"X9\"]])\n",
    "ordinal_enconder_X8=OrdinalEncoder(categories=[['Very Old', 'Old', 'Recent']])\n",
    "test_df[\"X8\"]=ordinal_enconder_X8.fit_transform(test_df[[\"X8\"]])\n",
    "\n",
    "one_hot_encoder=OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n",
    "categorical_cols=['X3','X5','X7','X10','X11']\n",
    "one_hot_features=one_hot_encoder.fit_transform(test_df[categorical_cols])\n",
    "one_hot_df=pd.DataFrame(one_hot_features,columns=one_hot_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Reset index to match original DataFrame\n",
    "one_hot_df.index = test_df.index\n",
    "\n",
    "# Drop original categorical columns\n",
    "test_df.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Concatenate the new one-hot encoded DataFrame with the original features\n",
    "test_df = pd.concat([test_df, one_hot_df], axis=1)\n",
    "test_df"
   ],
   "id": "9d8623fc00586029",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = best_model.predict(test_df)\n",
    "pd.DataFrame({'row_id': test_df.index, 'Y': y_pred}).to_csv('../AI Talents League - Round 1/predictionsTXGBOOST.csv', index=False)\n"
   ],
   "id": "7a97cb2654ae1026",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e57b574f7be4fcd8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
